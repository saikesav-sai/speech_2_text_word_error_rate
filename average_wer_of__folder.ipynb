{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cer(reference, hypothesis):\n",
    "    \"\"\"\n",
    "    Calculate Character Error Rate (CER) between reference and hypothesis strings.\n",
    "    CER is the percentage of characters that are incorrect in the hypothesis compared to the reference.\n",
    "    \"\"\"\n",
    "    reference = reference.lower()\n",
    "    hypothesis = hypothesis.lower()\n",
    "\n",
    "    # Create a matrix to store the distances between substrings\n",
    "    dp = [[0] * (len(hypothesis) + 1) for _ in range(len(reference) + 1)]\n",
    "\n",
    "    for i in range(len(reference) + 1):\n",
    "        for j in range(len(hypothesis) + 1):\n",
    "            if i == 0:\n",
    "                dp[i][j] = j\n",
    "            elif j == 0:\n",
    "                dp[i][j] = i\n",
    "            elif reference[i - 1] == hypothesis[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(dp[i][j - 1],      # Insert\n",
    "                                   dp[i - 1][j],      # Remove\n",
    "                                   dp[i - 1][j - 1])  # Replace\n",
    "\n",
    "    # Calculate CER as the normalized edit distance\n",
    "    cer = dp[len(reference)][len(hypothesis)] / len(reference)\n",
    "    return cer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_wer_and_cer(csv_files):\n",
    "    total_wer = 0\n",
    "    total_cer = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            with open(csv_file, 'r', newline='', encoding='utf-8') as file:\n",
    "                reader = csv.reader(file)\n",
    "                header = next(reader)  # Read header row\n",
    "                wer_index = header.index('WER')  # Find index of 'WER' column\n",
    "                expected_text_index = header.index('Expected Text')\n",
    "                generated_text_index = header.index('Generated Text')\n",
    "\n",
    "                for row in reader:\n",
    "                    wer = float(row[wer_index])\n",
    "                    total_wer += wer\n",
    "                    expected_text = row[expected_text_index]\n",
    "                    generated_text = row[generated_text_index]\n",
    "                    cer = calculate_cer(expected_text, generated_text)\n",
    "                    total_cer += cer\n",
    "                    num_samples += 1\n",
    "        except UnicodeDecodeError:\n",
    "            print(f'UnicodeDecodeError encountered in file {csv_file}, trying with ISO-8859-1 encoding.')\n",
    "            with open(csv_file, 'r', newline='', encoding='ISO-8859-1') as file:\n",
    "                reader = csv.reader(file)\n",
    "                header = next(reader)  # Read header row\n",
    "                wer_index = header.index('WER')  # Find index of 'WER' column\n",
    "                expected_text_index = header.index('Expected Text')\n",
    "                generated_text_index = header.index('Generated Text')\n",
    "\n",
    "                for row in reader:\n",
    "                    wer = float(row[wer_index])\n",
    "                    total_wer += wer\n",
    "                    expected_text = row[expected_text_index]\n",
    "                    generated_text = row[generated_text_index]\n",
    "                    cer = calculate_cer(expected_text, generated_text)\n",
    "                    total_cer += cer\n",
    "                    num_samples += 1\n",
    "\n",
    "    if num_samples > 0:\n",
    "        average_wer = total_wer / num_samples\n",
    "        average_cer = total_cer / num_samples\n",
    "        return average_wer, average_cer\n",
    "    else:\n",
    "        return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_average_wer_and_cer_to_csv(pattern, average_wer, average_cer, output_csv):\n",
    "    file_exists = os.path.isfile(output_csv)\n",
    "    with open(output_csv, 'a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if not file_exists:\n",
    "            writer.writerow(['Pattern', 'Average WER', 'Average CER'])\n",
    "        writer.writerow([pattern, average_wer, average_cer])\n",
    "\n",
    "def process_files_with_pattern(pattern, input_path, output_csv):\n",
    "    search_pattern = f'{pattern}-*.csv'\n",
    "    input_file = os.path.join(input_path, search_pattern)\n",
    "\n",
    "    matching_files = glob.glob(input_file)\n",
    "    if not matching_files:\n",
    "        print(f'No files found for pattern {pattern}')\n",
    "        return\n",
    "\n",
    "    average_wer, average_cer = calculate_average_wer_and_cer(matching_files)\n",
    "    append_average_wer_and_cer_to_csv(pattern, average_wer, average_cer, output_csv)\n",
    "    print(f'Average WER and CER for pattern {pattern} saved to {output_csv}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average WER and CER for pattern 1089 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 1188 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 121 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 1221 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 1284 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 1320 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 1580 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 1995 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 2094 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 2300 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 237 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 260 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 2830 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 2961 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 3570 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 3575 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 3729 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 4077 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 4446 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 4507 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 4970 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 4992 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 5105 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 5142 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 5639 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 5683 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 61 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 672 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 6829 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 6930 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 7021 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 7127 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 7176 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 7729 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 8224 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 8230 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 8455 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 8463 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 8555 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n",
      "Average WER and CER for pattern 908 saved to ..\\outputs\\libri_dataset_outputs\\noise_word_vec\\grouped\\noise_word_vec_folder_grouped_WER_CER_output.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage:\n",
    "input_path = r\"..\\outputs\\libri_dataset_outputs\\denoised_word_vec\\without_group\"\n",
    "output_csv = r\"..\\outputs\\libri_dataset_outputs\\denoised_word_vec\\grouped\\denoised_word_vec_folder_grouped_WER_CER_output.csv\"\n",
    "dataset_folder = r\"..\\dataset\\LibriSpeech\\test-clean\"\n",
    "\n",
    "for level1 in [f.name for f in os.scandir(dataset_folder) if f.is_dir()]:\n",
    "    pattern = level1\n",
    "    process_files_with_pattern(pattern, input_path, output_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
