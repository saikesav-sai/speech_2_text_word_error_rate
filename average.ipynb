{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_average_wer(csv_files):\n",
    "    total_wer = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            with open(csv_file, 'r', newline='', encoding='utf-8') as file:\n",
    "                reader = csv.reader(file)\n",
    "                header = next(reader)  # Read header row\n",
    "                wer_index = header.index('WER')  # Find index of 'WER' column\n",
    "\n",
    "                for row in reader:\n",
    "                    wer = float(row[wer_index])\n",
    "                    total_wer += wer\n",
    "                    num_samples += 1\n",
    "        except UnicodeDecodeError:\n",
    "            print(f'UnicodeDecodeError encountered in file {csv_file}, trying with ISO-8859-1 encoding.')\n",
    "            with open(csv_file, 'r', newline='', encoding='ISO-8859-1') as file:\n",
    "                reader = csv.reader(file)\n",
    "                header = next(reader)  # Read header row\n",
    "                wer_index = header.index('WER')  # Find index of 'WER' column\n",
    "\n",
    "                for row in reader:\n",
    "                    wer = float(row[wer_index])\n",
    "                    total_wer += wer\n",
    "                    num_samples += 1\n",
    "\n",
    "    if num_samples > 0:\n",
    "        average_wer = total_wer / num_samples\n",
    "        return average_wer\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_average_wer_to_csv(pattern, average_wer, output_csv):\n",
    "    file_exists = os.path.isfile(output_csv)\n",
    "    with open(output_csv, 'a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if not file_exists:\n",
    "            writer.writerow(['Pattern', 'Average WER'])\n",
    "        writer.writerow([pattern, average_wer])\n",
    "\n",
    "def process_files_with_pattern(pattern, input_path, output_csv):\n",
    "    search_pattern = f'{pattern}-*.csv'\n",
    "    input_file = os.path.join(input_path, search_pattern)\n",
    "\n",
    "    matching_files = glob.glob(input_file)\n",
    "    if not matching_files:\n",
    "        print(f'No files found for pattern {pattern}')\n",
    "        return\n",
    "\n",
    "    average_wer = calculate_average_wer(matching_files)\n",
    "    append_average_wer_to_csv(pattern, average_wer, output_csv)\n",
    "    print(f'Average WER for pattern {pattern} saved to {output_csv}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average WER for pattern 260 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 2830 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "UnicodeDecodeError encountered in file outputs\\libri_dataset_outputs\\noise_wer\\without_group\\2961-961.csv, trying with ISO-8859-1 encoding.\n",
      "Average WER for pattern 2961 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 3570 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 3575 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 3729 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 4077 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 4446 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 4507 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 4970 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 4992 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 5105 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 5142 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 5639 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 5683 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 61 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 672 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 6829 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 6930 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 7021 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 7127 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 7176 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 7729 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 8224 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average WER for pattern 8230 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 8455 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 8463 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 8555 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n",
      "Average WER for pattern 908 saved to outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "input_path = r\"outputs\\libri_dataset_outputs\\noise_wer\\without_group\"\n",
    "output_csv = r\"outputs\\libri_dataset_outputs\\noise_wer\\grouped\\noise_added_WER_output.csv\"\n",
    "dataset_folder = r\"dataset\\LibriSpeech\\test-clean\"\n",
    "\n",
    "for level1 in [f.name for f in os.scandir(dataset_folder) if f.is_dir()]:\n",
    "    pattern = level1\n",
    "    process_files_with_pattern(pattern, input_path, output_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
