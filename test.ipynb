{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\study\\codes\\engineering_codes\\research\\conda_env\\lib\\site-packages\\transformers\\models\\wav2vec2\\tokenization_wav2vec2.py:720: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HE BEGAN A CONFUSED COMPLAINT AGAINST THE WIZARD WHO HAD VANISHED BEHIND THE CURTAIN ON THE LY\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import speech_recognition as sr\n",
    "from evaluate import load\n",
    "wer = load(\"wer\")\n",
    "from jiwer import wer\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
    "import soundfile as sf\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "from scipy.signal import wiener\n",
    "import librosa\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read CSV file and process data\n",
    "def read_csv_file(csv_file):\n",
    "    data = []\n",
    "    with open(csv_file, 'r') as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        for row in reader:\n",
    "            number_part = row['Number']\n",
    "            text_part = row['Text'].strip()\n",
    "            data.append((number_part, text_part))\n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply Weiner filter and denoise audio\n",
    "def apply_weiner_filter(audio_file_path, output_file_path):\n",
    "    sample_rate, audio_data = wavfile.read(audio_file_path)\n",
    "    audio_data = audio_data.astype(np.float32) / np.max(np.abs(audio_data))\n",
    "    denoised_audio = wiener(audio_data)\n",
    "    denoised_audio = (denoised_audio * np.iinfo(np.int16).max).astype(np.int16)\n",
    "    wavfile.write(output_file_path, sample_rate, denoised_audio)\n",
    "    return output_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to convert wav file to text\n",
    "def convert_wav_to_text(audio_file_path):\n",
    "    # Load pre-trained model and tokenizer\n",
    "    model = Wav2Vec2ForCTC.from_pretrained(\"../models/word_vec\")\n",
    "    tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"../models/word_vec/tokenizer\")\n",
    "\n",
    "    # Load audio file\n",
    "    audio_input, _ = librosa.load(audio_file_path, sr=16000)\n",
    "\n",
    "    # Tokenize and convert to input features\n",
    "    input_values = tokenizer(audio_input, return_tensors=\"pt\").input_values\n",
    "\n",
    "    # Transcribe audio\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "\n",
    "    # Decode the transcription\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = tokenizer.batch_decode(predicted_ids)[0]\n",
    "\n",
    "    return transcription\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process data and generate WER\n",
    "def process_data_and_generate_wer(data, input_path, output_file):\n",
    "    with open(output_file, 'w', newline='') as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow(['Number', 'Expected Text', 'Generated Text', 'WER'])\n",
    "        \n",
    "        for number_part, expected_text in data:\n",
    "            wav_file = os.path.join(input_path, f\"{number_part}.wav\")  # audio file path\n",
    "            denoised_wav_file = os.path.join(input_path, f\"denoised_{number_part}.wav\")\n",
    "            \n",
    "            # Apply Weiner filter to the audio file\n",
    "            denoised_wav_file = apply_weiner_filter(wav_file, denoised_wav_file)\n",
    "            \n",
    "            # Convert denoised wav file to text\n",
    "            generated_text = convert_wav_to_text(denoised_wav_file)\n",
    "            \n",
    "            error_rate = wer(normalize_text(expected_text), normalize_text(generated_text))\n",
    "            writer.writerow([number_part, expected_text, generated_text, error_rate])\n",
    "            print(f\"Processed {wav_file} - WER: {error_rate}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your main dataset folder\n",
    "dataset_folder = r\"..\\dataset\\LibriSpeech\\test-clean\"\n",
    "output_folder = r\"..\\outputs\\libri_dataset_outputs\\noise_word_vec\\without_group\"\n",
    "\n",
    "for level1 in [f.name for f in os.scandir(dataset_folder) if f.is_dir()]:\n",
    "    level1_name = level1\n",
    "    level1 = os.path.join(dataset_folder, level1)\n",
    "\n",
    "    for level2 in [f.name for f in os.scandir(level1) if f.is_dir()]:\n",
    "        level2_name = level2\n",
    "        level2 = os.path.join(level1, level2)\n",
    "        level2 = os.path.join(level2, 'output')\n",
    "        input_path = os.path.join(level2, 'noise_added')\n",
    "\n",
    "        #to check normal file wer \n",
    "        # input_path=level2\n",
    "       \n",
    "\n",
    "        for allfiles in [f.name for f in os.scandir(level2)]:\n",
    "            if allfiles.endswith('.csv'):\n",
    "                csv_file = os.path.join(level2, allfiles)\n",
    "\n",
    "                # Interpret the CSV file and get number and text part\n",
    "                data = read_csv_file(csv_file)\n",
    "\n",
    "                # Creating output file to save in outputs directory\n",
    "                output_file_without_path = f\"{level1_name}-{level2_name}.csv\"\n",
    "                output_file = os.path.join(output_folder, output_file_without_path)\n",
    "\n",
    "                # We need data [number part, text part], input_path [which contains all .wav files], output_file [to store the final outputs]\n",
    "                process_data_and_generate_wer(data, input_path, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
